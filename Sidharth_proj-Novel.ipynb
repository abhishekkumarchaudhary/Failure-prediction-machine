{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ESynj51E6zYz"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from math import ceil\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tllmGoCL9GmR",
    "outputId": "6bc4dbae-125b-4967-9fd4-7573ae2284b2"
   },
   "outputs": [],
   "source": [
    "telemetry_df = pd.read_csv('azure/PdM_telemetry.csv') #Reading telemetry data (Volt,rpm,pressure,vibration)\n",
    "telemetry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJvpRYxf-QwZ",
    "outputId": "54d801d9-154f-45aa-8a8d-5c4dd6bac00a"
   },
   "outputs": [],
   "source": [
    "telemetry_df['datetime'].min(), telemetry_df['datetime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Lw0nG8m-V9l",
    "outputId": "2c6ca29b-ca67-4bad-db33-c8167d818d6e"
   },
   "outputs": [],
   "source": [
    "telemetry_df['machineID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "bPEjxc5V-YrE",
    "outputId": "61f94bf8-7512-449a-89c8-4e32628e0a23"
   },
   "outputs": [],
   "source": [
    "telemetry_df[['volt', 'rotate', 'pressure', 'vibration']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSa60WkL-beX",
    "outputId": "1c5e7b4f-ce63-44c5-8ff6-9279f0a77585"
   },
   "outputs": [],
   "source": [
    "telemetry_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "l8cEigZS-eUH",
    "outputId": "8b29f433-427a-48b2-dc64-758b1ed631a2"
   },
   "outputs": [],
   "source": [
    "failures = pd.read_csv('azure/PdM_failures.csv')\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-Ui-CQcS_HCf",
    "outputId": "29c633a8-d458-4a43-e05a-6d7f1e5d3784"
   },
   "outputs": [],
   "source": [
    "failures = failures.sort_values(by='datetime')\n",
    "failures.reset_index(inplace=True, drop=True)\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Otom3QHR_M0v",
    "outputId": "47d2cf06-48c8-436d-d554-b03cfebc9378"
   },
   "outputs": [],
   "source": [
    "failures['failure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1vEnELeN_Pgs"
   },
   "outputs": [],
   "source": [
    "telemetry_with_failure_df = telemetry_df.merge(failures, on=['datetime', 'machineID'], how='left')\n",
    "telemetry_with_failure_df.fillna('No Failure', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIkKk6vG_TQX",
    "outputId": "809d1813-5b7d-4a94-b09c-26448c069983"
   },
   "outputs": [],
   "source": [
    "telemetry_with_failure_df['failure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xVGF36M1_Wih",
    "outputId": "a93b35d0-ab4f-416c-e5e2-dc30eeab6204"
   },
   "outputs": [],
   "source": [
    "machine_info = pd.read_csv('azure/PdM_machines.csv')\n",
    "machine_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "pVD33L_j_YxI",
    "outputId": "02fd95b9-bbeb-4636-97f4-fc22091150c7"
   },
   "outputs": [],
   "source": [
    "telemetry_with_failure_df = machine_info.merge(right=telemetry_with_failure_df, on=['machineID'], how='left')\n",
    "telemetry_with_failure_df.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2tAGO_L_f-s",
    "outputId": "fa2b011a-53a5-4bd1-c4e3-28cdd098dbbe"
   },
   "outputs": [],
   "source": [
    "telemetry_with_failure_df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HJ0YKQ6Q_iCm"
   },
   "outputs": [],
   "source": [
    "def strToDatetime(date_array, format):\n",
    "    new_datetime = list()\n",
    "    for date in date_array:\n",
    "        new_datetime.append(datetime.datetime.strptime(date, format))\n",
    "    return new_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "utCgRAVGAEms"
   },
   "outputs": [],
   "source": [
    "datetime_column = strToDatetime(telemetry_with_failure_df['datetime'], '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IiXODEtFAHnI"
   },
   "outputs": [],
   "source": [
    "telemetry_with_failure_df['datetime'] = datetime_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOTSH1YaALBh",
    "outputId": "def3c155-b62d-49bc-b1d6-6254df7bb633"
   },
   "outputs": [],
   "source": [
    "telemetry_with_failure_df['datetime'].min(), telemetry_with_failure_df['datetime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtXecxweAQHP",
    "outputId": "a9802ad3-64cd-4fe0-95e5-b99aaa03c29a"
   },
   "outputs": [],
   "source": [
    "machine_ids = np.arange(1, 101)\n",
    "len(machine_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZdAfnTIvAS9_"
   },
   "outputs": [],
   "source": [
    "def hours_estimation(machine_id):\n",
    "    df = telemetry_with_failure_df[telemetry_with_failure_df['machineID'] == machine_id]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    rul = []\n",
    "    cont = len(df['failure']) - 1\n",
    "    diff = 0\n",
    "    while cont >= df.index.min():\n",
    "        if df['failure'][cont] == 'No Failure':\n",
    "            diff = diff + 1\n",
    "            rul.append(diff)\n",
    "        else:\n",
    "            rul.append(0)\n",
    "            diff = 0\n",
    "        diff = rul[-1]\n",
    "        cont = cont - 1\n",
    "    df['hours_to_fail'] = list(reversed(rul))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GziLAal-AVlB"
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for machine_id in machine_ids:\n",
    "    df = hours_estimation(machine_id)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "90P5oFEjAYcQ"
   },
   "outputs": [],
   "source": [
    "telemetry = pd.DataFrame()\n",
    "for df in dfs:\n",
    "    telemetry = pd.concat([telemetry, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHTLoi5PAbGB",
    "outputId": "c086b575-29ef-4f0e-ca07-4f0230709c57"
   },
   "outputs": [],
   "source": [
    "print(telemetry.shape[0], telemetry_with_failure_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6lG2YzLKAfIg",
    "outputId": "81c77a6f-4626-4a77-f0c5-23b93dc0bcac"
   },
   "outputs": [],
   "source": [
    "telemetry['seconds_to_fail'] = telemetry['hours_to_fail'] * 3600\n",
    "telemetry.drop('hours_to_fail', axis=1, inplace=True)\n",
    "telemetry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "B1JIuHPsAhsx",
    "outputId": "0939cd70-fb02-4b30-aacc-1993f03f584b"
   },
   "outputs": [],
   "source": [
    "# sns.heatmap(telemetry.corr(), annot=True).figure.set_size_inches(12, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bzkU4uUcAo56",
    "outputId": "29fe5e52-e7ec-4cd8-8c0c-61c687fd9fb6"
   },
   "outputs": [],
   "source": [
    "telemetry.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yn6BkP8ArAw",
    "outputId": "540adae8-4fe6-4562-bad3-009bbf219a6e"
   },
   "outputs": [],
   "source": [
    "datetimes = telemetry['datetime']\n",
    "timestamps = list()\n",
    "for datetime_ in datetimes:\n",
    "    timestamps.append(datetime.datetime.timestamp(datetime_))    \n",
    "datetimes.shape[0], len(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "xZhqvCxQAtUt",
    "outputId": "b3be12cc-e093-487b-b57c-e6f20aa6151b"
   },
   "outputs": [],
   "source": [
    "telemetry['timestamp'] = timestamps\n",
    "#telemetry.drop('datetime', axis=1, inplace=True)\n",
    "#telemetry = telemetry[['timestamp', 'machineID', 'model', 'age', 'volt', 'rotate', 'pressure', 'vibration', 'failure', 'seconds_to_fail']]\n",
    "telemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 788
    },
    "id": "K-BBq1heAwUL",
    "outputId": "2f00c639-dbf6-4cf2-e2d5-55f87fd5ba27"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=telemetry['model'], y=telemetry['seconds_to_fail'], order=['model1', 'model2', 'model3', 'model4']).figure.set_size_inches(12, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oIUT7B9A3wC",
    "outputId": "e8a36f38-20cb-4027-e810-439a834e9ef1"
   },
   "outputs": [],
   "source": [
    "telemetry['model'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Make change for model here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "l4sAY2uoA9xZ",
    "outputId": "71ac9cfc-12a6-43bb-8647-94eeb60e3df6"
   },
   "outputs": [],
   "source": [
    "model3_data = telemetry[telemetry['model'] == 'model3'].reset_index(drop=True)\n",
    "model3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Ii_RyemBBBtB"
   },
   "outputs": [],
   "source": [
    "def create_time_step(data, machine_id):\n",
    "    machine_id_data = data[data['machineID'] == machine_id]\n",
    "    time_step = np.arange(1, machine_id_data.shape[0]+1)\n",
    "    machine_id_data['time_step'] = time_step\n",
    "    return machine_id_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xiOqP-0BFyF",
    "outputId": "6d8ed8e5-843d-4534-8237-ebda430288bd"
   },
   "outputs": [],
   "source": [
    "machineIDs = model3_data['machineID'].unique()\n",
    "dataframes_with_time_step = []\n",
    "for machine_id in machineIDs:\n",
    "    dataframes_with_time_step.append(create_time_step(model3_data, machine_id))\n",
    "len(dataframes_with_time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "72kU4J_YBKJi"
   },
   "outputs": [],
   "source": [
    "model3_data = pd.DataFrame()\n",
    "for df in dataframes_with_time_step:\n",
    "    model3_data = pd.concat([model3_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "6BO0KTicBMka",
    "outputId": "dfb0ff21-1603-4040-ec10-bd1e22c1becf"
   },
   "outputs": [],
   "source": [
    "#model3_data = model3_data[['age', 'volt', 'rotate', 'pressure', 'vibration', 'seconds_to_fail']]\n",
    "model3_data.drop(['model', 'failure', 'datetime', 'timestamp', 'machineID'], axis=1, inplace=True)\n",
    "model3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6QzsSJ3_BPKX",
    "outputId": "2d282740-b104-4c5e-cf29-7b3d5f0b0386"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "normalized_telemetry = pd.DataFrame(data=scaler.fit_transform(model3_data), columns=model3_data.columns)\n",
    "normalized_telemetry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fwtqiVIBR1I",
    "outputId": "a7c00ddb-b771-4fb1-a8f4-9e7a904b9f83"
   },
   "outputs": [],
   "source": [
    "#Split in 80-20% without random\n",
    "train_size = ceil(normalized_telemetry.shape[0] * 0.8)\n",
    "test_size = ceil(normalized_telemetry.shape[0] * 0.2)\n",
    "print(f'Train size: {train_size}')\n",
    "print(f'Test size: {test_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ABw9QVl0BazG",
    "outputId": "0fc9bdca-7458-489e-b13a-da54d9d21fa3"
   },
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# normalized_telemetry = pd.DataFrame(data=scaler.fit_transform(model3_data), columns=model3_data.columns)\n",
    "# normalized_telemetry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3b6PoHEBw5c",
    "outputId": "94d2832a-332a-4ff8-f243-30ca70027278"
   },
   "outputs": [],
   "source": [
    "#Resetting index for split\n",
    "train_set = normalized_telemetry[:train_size]\n",
    "\n",
    "test_set = normalized_telemetry[train_size:].reset_index(drop=True)\n",
    "\n",
    "train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gv1I_m-DBoFj",
    "outputId": "b8e24a69-251a-4fe4-dd25-0405025120cf"
   },
   "outputs": [],
   "source": [
    "# train_size = ceil(normalized_telemetry.shape[0] * 0.7)\n",
    "# test_and_val_size = ceil((normalized_telemetry.shape[0] * 0.3) / 2)\n",
    "# print(f'Train size: {train_size}')\n",
    "# print(f'Test and validation size: {test_and_val_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "7g4mHPArBqzC"
   },
   "outputs": [],
   "source": [
    "X_train = train_set.drop('seconds_to_fail', axis=1)\n",
    "X_train = np.array(X_train)\n",
    "y_train = train_set['seconds_to_fail']\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = test_set.drop('seconds_to_fail', axis=1)\n",
    "X_test = np.array(X_test)\n",
    "y_test = test_set['seconds_to_fail']\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# X_valid = val_set.drop('seconds_to_fail', axis=1)\n",
    "# X_valid = np.array(X_valid)\n",
    "# y_valid = val_set['seconds_to_fail']\n",
    "# y_valid = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "fRv5lH1Z46jp"
   },
   "outputs": [],
   "source": [
    "def print_plot(y_test, predict):\n",
    "  error = mean_absolute_error(y_test, predict)\n",
    "  print(f'MAE:{error}')\n",
    "  mse = mean_squared_error(y_test, predict)\n",
    "  print(f'MSE:{mse}')\n",
    "  X = np.arange(y_test.shape[0])\n",
    "#   plt.plot(y_test, color='red')\n",
    "  plt.scatter(X,y_test, color='red',s=1)\n",
    "#   plt.plot(predict, color='blue')\n",
    "  plt.scatter(X,predict, color='blue',s=1)\n",
    "  plt.ylim([0, 0.7])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bidiectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
    "from keras.layers import Add\n",
    "\n",
    "#Data transfer\n",
    "train_data = X_train  \n",
    "train_labels = y_train \n",
    "test_data = X_test\n",
    "test_labels = y_test\n",
    "# s\n",
    "# Create the BiLSTM model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, activation='relu'), input_shape=(None, 6)))\n",
    "model.add(Dense(1))  # Output layer with a single neuron for forecasting\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Reshape the data for compatibility with BiLSTM input shape\n",
    "train_data = np.reshape(train_data, (train_data.shape[0], 1, train_data.shape[1]))\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], 1, test_data.shape[1]))\n",
    "\n",
    "#Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32)\n",
    "\n",
    "# # # Evaluate the model\n",
    "# # mse = model.evaluate(test_data, test_labels)\n",
    "# # print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# # # Make predictions\n",
    "# # predictions = model.predict(test_data)\n",
    "#Evaluate the model\n",
    "mse = model.evaluate(test_data, test_labels)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Make predictions\n",
    "predict = model.predict(test_data)\n",
    "print_plot(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LSTM(RNN) with skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Add\n",
    "#Data transfer\n",
    "train_data = X_train  \n",
    "train_labels = y_train \n",
    "test_data = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=(None, 6))\n",
    "\n",
    "# Define the LSTM layer with skip connection\n",
    "lstm_layer = LSTM(6, activation='relu', return_sequences=True)(input_layer)\n",
    "skip_layer = Add()([input_layer, lstm_layer]) #concatenate([input_layer, lstm_layer])\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = LSTM(64, activation='relu')(skip_layer)\n",
    "output_layer = Dense(1)(output_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Reshape the data for compatibility with RNN input shape\n",
    "train_data = np.reshape(train_data, (train_data.shape[0], 1, train_data.shape[1]))\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], 1, test_data.shape[1]))\n",
    "\n",
    "#Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32)\n",
    "\n",
    "# # Evaluate the model\n",
    "# # mse = model.evaluate(test_data, test_labels)\n",
    "# # print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# # Make predictions\n",
    "# # predictions = model.predict(test_data)\n",
    "\n",
    "# mse = model.evaluate(test_data, test_labels)\n",
    "# print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Make predictions\n",
    "predict = model.predict(test_data)\n",
    "print_plot(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "#Data transfer\n",
    "train_data = X_train  \n",
    "train_labels = y_train \n",
    "test_data = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Create the stacked LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', return_sequences=True, input_shape=(None, 6)))\n",
    "model.add(LSTM(64, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer with a single neuron for forecasting\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Reshape the data for compatibility with LSTM input shape\n",
    "train_data = np.reshape(train_data, (train_data.shape[0], 1, train_data.shape[1]))\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], 1, test_data.shape[1]))\n",
    "\n",
    "#Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mse = model.evaluate(test_data, test_labels)\n",
    "# print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Make predictions\n",
    "predict = model.predict(test_data)\n",
    "print_plot(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional layer\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    # Max pooling layer\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Flatten the output\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Dense (fully connected) layers\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1))  # Output layer (1 node for regression)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions\n",
    "# predictions = model.predict(test_data)\n",
    "# print_plot(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Reshape the input data to fit the CNN model\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "# Create the CNN model\n",
    "input_shape = X_train.shape[1:]\n",
    "model = create_cnn_model(input_shape)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# loss = model.evaluate(X_test, y_test)\n",
    "# print(\"Test Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predict = model.predict(X_test)\n",
    "print_plot(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet replica on 1D tabular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Add\n",
    "Input_layer = Input(shape=input_shape)\n",
    "x = Conv1D(filters=32, kernel_size=3, padding = 'same', activation='relu', input_shape=input_shape)(Input_layer)\n",
    "x = Conv1D(filters=32, kernel_size=3, padding = 'same', activation='relu')(x)\n",
    "y = Add()([x, Input_layer])\n",
    "temp = x\n",
    "x = Conv1D(filters=32, kernel_size=3, padding = 'same', activation='relu')(y)\n",
    "z = Add()([x, temp])\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(1)(x)  # Output layer (1 node for regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=Input_layer, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_data = X_test\n",
    "predict = model.predict(test_data)\n",
    "print_plot(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate some random tabular data for demonstration\n",
    "train_data = X_train  \n",
    "train_labels = y_train \n",
    "test_data = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(None, 6)))\n",
    "model.add(Dense(1))  # Output layer with a single neuron for forecasting\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Reshape the data for compatibility with LSTM input shape\n",
    "train_data = np.reshape(train_data, (train_data.shape[0], 1, train_data.shape[1]))\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], 1, test_data.shape[1]))\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32)\n",
    "predict = model.predict(test_data)\n",
    "print_plot(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "train_data = X_train  \n",
    "train_labels = y_train \n",
    "test_data = X_test\n",
    "test_labels = y_test\n",
    "\n",
    "# Create the CNN+LSTM hybrid model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(6, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Reshape((1, 64)))  # Reshape output of Flatten layer to (batch_size, 1, 64)\n",
    "model.add(LSTM(64, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer with a single neuron for forecasting\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Reshape the data for compatibility with CNN+LSTM input shape\n",
    "train_data = np.reshape(train_data, (train_data.shape[0], train_data.shape[1], 1))\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], 1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, batch_size=32)\n",
    "predict = model.predict(test_data)\n",
    "print_plot(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
